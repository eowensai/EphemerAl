# EphemerAl

Looking for a complete solution to host a web-based AI service on your local network? Skip the costs and data risks of online platforms by running Google’s Gemma 3 LLM on your own hardware. Gemma 3 is the highest-rated open-weight LLM that’s practical to run on consumer-grade systems: https://lmarena.ai/leaderboard/text

EphemerAl is a lightweight, self-hosted AI interface designed with local data privacy in mind. No chat history is stored and nothing leaves your network. The included Setup Guide walks you through configuring its Ollama/Gemma 3/Tika backend. All responses are generated by Gemma 3 (12b or 27b), and enhanced by any documents, images, or queries you attach during a conversation.

This project began as a personal effort to solve a problem at my workplace. I’m not a developer by trade, but I used AI tools to help bring it to life. While it wasn’t built for broad distribution, I’m sharing this generalized version in case it helps others looking for a secure, account-free, multimodal LLM interface. . . whether for internal tools, training environments, or experimentation.

---

## Core Features of the solution:

* **🤖 AI Assistant:** Real-time chat interface powered by Google’s Gemma 3 IT QAT LLM, served locally via Ollama
* **📄 Document Upload:** Supports 100+ file types through Apache Tika, injecting full text directly into queries
* **🖼️ Multimodal Support:** Use Gemma 3’s built-in capability to analyze images alongside text
* **🎨 Customizable Interface:** Clean, minimal UI with optional logo or image block for lightweight branding
* **🔒 Ephemeral** No session data is stored. All processing runs locally. No internet access is required after initial setup

---

## Architecture

EphemerAl is a containerized web app designed to run fully offline after initial setup. It uses Docker Compose and Windows Subsystem for Linux 2 (WSL2) to create a clean, isolated environment on your existing Windows 11 Pro or Enterprise system.

There’s no installer. Instead, you follow a detailed step-by-step deployment guide. Every command is provided, and no prior Docker or WSL experience is required.

Once deployed, the system runs entirely on your local hardware—no cloud connection, no user accounts, and no data persistence unless you build it in.

**Stack Overview:**

* **Windows 11 Pro/Enterprise Host**

  * **WSL2 (Ubuntu 24.04):** Lightweight Linux VM managed by Windows

    * **Docker Engine:** Manages isolated service containers:

      * `ephemeral-app`: Streamlit-based user interface
      * `ollama`: Local LLM backend using Ollama to serve Gemma 3
      * `tika-server`: Apache Tika for document parsing and extraction

---

## System Requirements & Setup

* **OS:** Windows 11 Pro or Enterprise (fully updated)
* **GPU:** At least one discrete NVIDIA GPU

  * 30-series or newer strongly recommended
  * 12GB+ VRAM suggested for smooth performance with Gemma 3 12B
* **Driver:** Latest WHQL NVIDIA GPU driver (you can skip optional installs like the Control Panel)

## Deployment

Follow the step-by-step instructions in the included **System Deployment Guide**. Most commands are ready to copy and paste into PowerShell.
Setup includes optional instructions for launching the app automatically at login (useful for unattended or kiosk-style deployments).

> A fully headless WSL setup was attempted but ultimately abandoned in favor of simplicity and reliability during operation.

## Access the Interface

* **From the server:**
  Visit [http://localhost:8501](http://localhost:8501)

* **From another machine on your network:**
  Replace `<windows_host_ip_address>` with the correct IP:
  `http://<windows_host_ip_address>:8501`

## Stopping the Application

To stop the application, open an elevated (Administrator) PowerShell window on the host and run:

```powershell
wsl --shutdown
```

To restart, either:

* Reboot and log in, or
* Run `wsl` again from PowerShell and leave the window open or minimized

## Support

No official support is provided. If you run into issues, I recommend:

* Pasting the error message into an AI assistant
* Including a screenshot and a brief description of your technical level

This improves the chances of getting helpful troubleshooting advice.

## Known Issues

* The UI doesn't render correctly on mobile.
* Minimizing the sidebar (where the logo lives) can't be undone without a refresh.
* User text may initially appear under the right arrow icon in the input box before wrapping correctly.
* Attachments disappear visually after submission, but their content remains in context for the model throughout the conversation.
* There is no guardrail for exceeding the model's `ctx` limit. Gemma 3 supports very long context windows, and I chose to defer graceful error handling unless this becomes a problem.

