# EphemerAl

Looking for a complete solution to host a web-based AI service on your local network? Skip the costs and data risks of online platforms by running Google‚Äôs Gemma 3 LLM on your own hardware. Gemma 3 is the highest-rated open-weight LLM that‚Äôs practical to run on consumer-grade systems: https://lmarena.ai/leaderboard/text

EphemerAl is a lightweight, self-hosted AI interface designed with local data privacy in mind. No chat history is stored and nothing leaves your network. The included Setup Guide walks you through configuring its Ollama/Gemma 3/Tika backend. All responses are generated by Gemma 3 (12b or 27b), and enhanced by any documents, images, or queries you attach during a conversation.

This project began as a personal effort to solve a problem at my workplace. I‚Äôm not a developer by trade, but I used AI tools to help bring it to life. While it wasn‚Äôt built for broad distribution, I‚Äôm sharing this generalized version in case it helps others looking for a secure, account-free, multimodal LLM interface. . . whether for internal tools, training environments, or experimentation.

---

## Core Features of the solution:

* **ü§ñ AI Assistant:** Real-time chat interface powered by Google‚Äôs Gemma 3 IT QAT LLM, served locally via Ollama
* **üìÑ Document Upload:** Supports 100+ file types through Apache Tika, injecting full text directly into queries
* **üñºÔ∏è Multimodal Support:** Use Gemma 3‚Äôs built-in capability to analyze images alongside text
* **üé® Customizable Interface:** Clean, minimal UI with optional logo or image block for lightweight branding
* **üîí Ephemeral** No session data is stored. All processing runs locally. No internet access is required after initial setup

---

## Architecture

EphemerAl is a containerized web app designed to run fully offline after initial setup. It uses Docker Compose and Windows Subsystem for Linux 2 (WSL2) to create a clean, isolated environment on your existing Windows 11 Pro or Enterprise system.

There‚Äôs no installer. Instead, you follow a detailed step-by-step deployment guide. Every command is provided, and no prior Docker or WSL experience is required.

Once deployed, the system runs entirely on your local hardware‚Äîno cloud connection, no user accounts, and no data persistence unless you build it in.

**Stack Overview:**

* **Windows 11 Pro/Enterprise Host**

  * **WSL2 (Ubuntu 24.04):** Lightweight Linux VM managed by Windows

    * **Docker Engine:** Manages isolated service containers:

      * `ephemeral-app`: Streamlit-based user interface
      * `ollama`: Local LLM backend using Ollama to serve Gemma 3
      * `tika-server`: Apache Tika for document parsing and extraction

---

## System Requirements & Setup

Windows 11 Pro or Enterprise, fully updated.
At least one discrete Nvidia GPU (30-series or newer recommended with 12GB+ VRAM, for Gemma 3 12B to perform well).
Latest WHQL Nvidia GPU driver (you can skip optional installs like the Control Panel).

## Deployment

Follow the steps in the included System Deployment Guide. Most commands can be copy/pasted into PowerShell.
Setup includes instructions on how to auto-launch at login (for easy recovery after reboot).
A headless WSL setup was attempted but ultimately abandoned to prioritize operational use.

## Access the Interface:

From the server: open a browser and go to http://localhost:8501
From another machine on the network: go to http://<windows_host_ip_address>:8501

## Stopping the Application

Open an elevated (admin) PowerShell window on the host and run:
wsl --shutdown
To restart: either reboot and log back in, or run wsl again in PowerShell and leave the window open or minimized.

## Support

No official support is provided.
I recommend pasting error messages or issues into an AI assistant, along with a screenshot and a description of your technical level. This will help the AI tailor troubleshooting guidance more effectively.

## Known Issues

* The UI is not rendered correctly in mobile.
* Minimizing the sidebar (where the logo lives) can't be undone, you have to refresh to get it back. I chose to live with it than spend more time troubleshooting.
* User text will type under the arrow in the far right side of the text window for a bit before starting a new line.
* Attachments disappear (visually) after being submitted in a query.  Again, not a big deal to me so didn't spend more time on it.  Confirmed the full text remains in context the whole conversation (relying on Gemma 3's attention).
* There isn't a guardrail if the user submits a query larger than available ctx.  Gemma 3 supports large ctx, and I punted trying to handle this cleanly until/if it becomes a problem.

